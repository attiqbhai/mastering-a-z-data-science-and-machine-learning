{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQm7hXJJxSBK7rIb+LJwMD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries needed by this notebook"
      ],
      "metadata": {
        "id": "R-FjyHMdYeji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt"
      ],
      "metadata": {
        "id": "1LZmqJZIYbCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.__version__"
      ],
      "metadata": {
        "id": "DuowMwONkUGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Series Object\n",
        "\n",
        "\n",
        "*   A pandas Series is a one-dimensional labelled array.\n",
        "*   A Series combines the best features of a list and a dictionary.\n",
        "*   A Series maintains a single collection of ordered values (i.e. a single column of data).\n",
        "*   We can assign each value an identifier, which does not have to be unique.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QY4yV-wHnRHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = pd.Series([2,5,7,9,11], index=[\"a\", \"b\",\"c\",\"d\",\"e\"])\n",
        "print(type(A))\n",
        "print(A)\n",
        "print(type(A.values))\n",
        "print(A.values)\n",
        "print(type(A.index))\n",
        "print(A.index)\n",
        "print(A[\"a\"])\n",
        "print(A[\"a\":\"c\"])"
      ],
      "metadata": {
        "id": "SbwgifvAkvuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Series Object from Dictionary\n",
        "\n",
        "\n",
        "*   The keys becomes identifiers and value becomes the items of the list.\n",
        "\n"
      ],
      "metadata": {
        "id": "sMFE3DxrnVNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grades_dic = { \"A\": 4, \"A-\": 3.5, \"B\": 3, \"B-\": 2.5, \"C\": 2}\n",
        "marks_dic = { \"A\": 85, \"A-\": 80, \"B\": 75, \"B-\": 70, \"C\": 65}\n",
        "\n",
        "grades_series = pd.Series(grades_dic)\n",
        "marks_series = pd.Series(marks_dic)\n",
        "\n",
        "print(grades_series)\n",
        "print(marks_series)"
      ],
      "metadata": {
        "id": "nIlnw6sInXzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to Series Methods\n",
        "\n",
        "\n",
        "\n",
        "*   Sum\n",
        "*   Product\n",
        "*   Mean\n",
        "*   std - Standard Deviation\n",
        "\n",
        "> Standard deviation is a measure of how spread out values are in a dataset.\n",
        "> *   Low standard deviation → values are close to the average\n",
        "> *   High standard deviation → values are widely spread out\n",
        "\n",
        "> Think of Standard deviation as the “typical distance” of data points from the mean.\n",
        "\n",
        "> #### Formal definition\n",
        "Standard deviation is the square root of the variance.\n",
        "\n",
        "> #### Why use it?\n",
        "> *   Understand variability in data\n",
        "> *   Compare consistency (e.g., test scores, sales, sensor readings)\n",
        "> *   Core to statistics, machine learning, and data analysis\n",
        "\n",
        "\n",
        "> #### Rule of thumb (normal distribution)\n",
        "> *   ~68% of values lie within ±1 std dev of the mean\n",
        "> *   ~95% within ±2 std dev\n",
        "> *   ~99.7% within ±3 std dev"
      ],
      "metadata": {
        "id": "i94AeCHvUEWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prices = pd.Series([2.99, 4.45, 1.36])\n",
        "\n",
        "print(\"-------The Series-------\")\n",
        "print(prices)\n",
        "\n",
        "print(\"-------The sum-------\")\n",
        "print(prices.sum())\n",
        "\n",
        "print(\"-------The product-------\")\n",
        "print(prices.product())\n",
        "\n",
        "print(\"-------The Means-------\")\n",
        "print(prices.mean())\n",
        "\n",
        "print(\"-------The Standard Deviation-------\")\n",
        "print(prices.std())"
      ],
      "metadata": {
        "id": "xuUDqjYUXp4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to Attributes\n",
        "\n",
        "*   An attribute is a piece of data that lives on an object.\n",
        "*   An attribute is a fact, a detail, a characteristic of the object.\n",
        "*   Access an attribute with object.attribute syntax.\n"
      ],
      "metadata": {
        "id": "rlWS78YiYnyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adjectives = pd.Series([\"Smart\",\"Handsome\", \"Charming\", \"Brilliant\", \"Humble\", \"Smart\"])\n",
        "print(f\"No Duplication: {adjectives.is_unique}\")\n",
        "print(f\"Values: {adjectives.values}\")\n",
        "print(f\"Index: {adjectives.index}\")"
      ],
      "metadata": {
        "id": "e-wcnUgxY9NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Series with the pd.read_csv Function\n",
        "\n",
        "*   Pandas ships with many different read_ functions for different types of files.\n",
        "*   The read_csv function accepts many different parameters. The first one specifies the file name/path.\n",
        "*   The read_csv function will import the dataset as a DataFrame, a 2-dimensional table.\n",
        "*   The usecols parameter accepts a list of the column(s) to import.\n",
        "*   The squeeze method converts a DataFrame to a Series.\n"
      ],
      "metadata": {
        "id": "OOOz1l0RpgAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pokeman_data = pd.read_csv(\"/content/sample_data/pokemon.csv\")\n",
        "print(type(pokeman_data))\n",
        "print(pokeman_data)\n",
        "print(\"------------------------------\")\n",
        "pokeman_data = pd.read_csv(\"/content/sample_data/pokemon.csv\", usecols=[\"Pokemon\"])\n",
        "print(type(pokeman_data))\n",
        "print(pokeman_data)\n",
        "print(\"------------Squeeze only works if dataframe has one column------------------\")\n",
        "pokeman_data = pd.read_csv(\"/content/sample_data/pokemon.csv\", usecols=[\"Pokemon\"]).squeeze('columns')\n",
        "print(type(pokeman_data))\n",
        "print(pokeman_data)"
      ],
      "metadata": {
        "id": "zEEh--Wctedq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_data = pd.read_csv(\"/content/sample_data/google_stock_price.csv\")\n",
        "print(type(google_data))\n",
        "print(google_data)\n",
        "print(\"------------------------------\")\n",
        "google_data = pd.read_csv(\"/content/sample_data/google_stock_price.csv\", usecols=[\"Stock Price\"])\n",
        "print(type(google_data))\n",
        "print(google_data)\n",
        "print(\"------------Squeeze only works if dataframe has one column------------------\")\n",
        "google_data = pd.read_csv(\"/content/sample_data/google_stock_price.csv\", usecols=[\"Stock Price\"]).squeeze('columns')\n",
        "print(type(google_data))\n",
        "print(google_data)\n",
        "print(\"------------Head and tail------------------\")\n",
        "google_data = pd.read_csv(\"/content/sample_data/google_stock_price.csv\", usecols=[\"Stock Price\"]).squeeze('columns')\n",
        "print(google_data.head(6))\n",
        "print(google_data.tail(6))\n",
        "\n"
      ],
      "metadata": {
        "id": "MID32mAtLn3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passing Series to Python's Built-In Functions\n",
        "\n",
        "\n",
        "\n",
        "*   The len function returns the length of the Series.\n",
        "*   The type function returns the type of an object.\n",
        "*   The list function converts the Series to a list.\n",
        "*   The dict function converts the Series to a dictionary.\n",
        "*   The sorted function converts the Series to a sorted list.\n",
        "*   The max function returns the largest value in the Series.\n",
        "*   The min function returns the smallest value in the Series.\n"
      ],
      "metadata": {
        "id": "4PYZBtLGoSB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(pokeman_data)\n",
        "type(google_data)\n",
        "list(pokeman_data)\n",
        "dict(pokeman_data)\n",
        "sorted(google_data)\n",
        "max(pokeman_data)\n",
        "min(pokeman_data)"
      ],
      "metadata": {
        "id": "PM_OvEJfpBG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read CSV and mark certain column as an Index column And sort by values/index"
      ],
      "metadata": {
        "id": "PtUkEaiV-iEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pokeman_data = pd.read_csv(\"/content/sample_data/pokemon.csv\", index_col=[\"Pokemon\"]).squeeze('columns')\n",
        "print(type(pokeman_data))\n",
        "print(pokeman_data)\n",
        "print(\"----------------Sort By Values--------------\")\n",
        "print(pokeman_data.sort_values())\n",
        "print(\"----------------Sprt by Index--------------\")\n",
        "print(pokeman_data.sort_index())"
      ],
      "metadata": {
        "id": "cIxw17m8-ptP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Series Value by Index Position\n",
        "\n",
        "\n",
        "\n",
        "*   Use the iloc accessor to extract a Series value by its index position.\n",
        "*   iloc is short for \"index location\".\n",
        "*   Python's list slicing syntaxes (slices, slices from start, slices to end, etc.) are supported with Series objects.\n",
        "\n"
      ],
      "metadata": {
        "id": "kHbiA4L8HAhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pokeman_data = pd.read_csv(\"/content/sample_data/pokemon.csv\").squeeze('columns')\n",
        "print(pokeman_data.iloc[[0,3,7]])\n",
        "print(\"------------------------------\")\n",
        "print(pokeman_data.iloc[100])\n",
        "print(\"------------------------------\")\n",
        "print(pokeman_data.iloc[0:5])\n",
        "print(\"--------------From start till index 4----------------\")\n",
        "print(pokeman_data.iloc[:5])\n",
        "print(\"--------------From 715 till end----------------\")\n",
        "print(pokeman_data.iloc[715:])\n",
        "print(\"--------------Pull last value in series----------------\")\n",
        "print(pokeman_data.iloc[-1])\n",
        "print(\"--------------Pull last five in series----------------\")\n",
        "print(pokeman_data.iloc[-5:-1])\n",
        "print(\"--------------Pull last five in series----------------\")\n",
        "print(pokeman_data.iloc[-5:])"
      ],
      "metadata": {
        "id": "NixiNElyKOtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Series Value by Index Label\n",
        "\n",
        "\n",
        "\n",
        "*   Use the loc accessor to extract a Series value by its index label.\n",
        "*   Pass a list to extract multiple values by index label.\n",
        "*   If one index label/position in the list does not exist, Pandas will raise an error.\n",
        "\n"
      ],
      "metadata": {
        "id": "kyrWYMiNO3nT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pokemon_data = pd.read_csv(\"/content/sample_data/pokemon.csv\", index_col=[\"Pokemon\"]).squeeze('columns')\n",
        "print(pokemon_data.loc[\"Venusaur\"])\n",
        "print(\"------------------------------\")\n",
        "print(pokemon_data.loc[[\"Venusaur\", \"Charmander\", \"Yveltal\"]])\n",
        "print(\"------------------------------\")\n",
        "print(pokemon_data.loc[\"Bulbasaur\":\"Charmeleon\"])"
      ],
      "metadata": {
        "id": "S81cHAISPPzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The get Method on a Series\n",
        "\n",
        "\n",
        "*   The get method extracts a Series value by index label. It is an alternative option to square brackets.\n",
        "*   The get method's second argument sets the fallback value to return if the label/position does not exist.\n",
        "\n"
      ],
      "metadata": {
        "id": "MjFdMfxIXd-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pokemon_data = pd.read_csv(\"/content/sample_data/pokemon.csv\", index_col=[\"Pokemon\"]).squeeze('columns')\n",
        "print(pokemon_data.get(\"Venusaur\"))\n",
        "print(\"------------------------------\")\n",
        "print(pokemon_data.get(\"Venusaur1\",\"missed\"))\n",
        "print(\"------------------------------\")\n",
        "print(pokemon_data.get(\"Venusaur\",\"missed\"))\n",
        "print(\"------------------------------\")\n",
        "print(pokemon_data.get([\"Bulbasaur1\",\"Charmeleon1\"], \"missed\"))\n",
        "None"
      ],
      "metadata": {
        "id": "D8XQatk_Xycv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overwrite a Series Value\n",
        "\n",
        "\n",
        "*   Use the loc/iloc accessor to target an index label/position, then use an equal sign to provide a new value.\n",
        "\n"
      ],
      "metadata": {
        "id": "AwzcLQQicfaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pokemon_data = pd.read_csv(\"/content/sample_data/pokemon.csv\", index_col=[\"Pokemon\"]).squeeze('columns')\n",
        "print(pokemon_data.loc[\"Venusaur\"])\n",
        "print(\"------------------------------\")\n",
        "pokemon_data.loc[\"Venusaur\"] = \"Electric\"\n",
        "print(\"------------------------------\")\n",
        "print(pokemon_data.loc[\"Venusaur\"])"
      ],
      "metadata": {
        "id": "3SDfuNMPclzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The copy Method\n",
        "\n",
        "\n",
        "*   A copy is a duplicate/replica of an object.\n",
        "*   Changes to a copy do not modify the original object.\n",
        "*   A view is a different way of looking at the same data.\n",
        "*   Changes to a view do modify the original object.\n",
        "*   The copy method creates a copy of a pandas object.\n",
        "\n"
      ],
      "metadata": {
        "id": "JJ8Ep5G3FQb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pokemon_dataset = pd.read_csv(\"/content/sample_data/pokemon.csv\", index_col=[\"Pokemon\"])\n",
        "pokemon_series = pokemon_dataset.squeeze('columns').copy()\n",
        "# Is series a view Or copy. This is a copy if you have used copy method.\n",
        "pokemon_series.loc[\"Bulbasaur\"] = \"Fire\"\n",
        "print(pokemon_series)\n",
        "print(pokemon_dataset)"
      ],
      "metadata": {
        "id": "gJMD7AUFFwEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Math Methods on Series Objects\n",
        "\n",
        "\n",
        "*   The count method returns the number of values in the Series. It excludes missing values; the size attribute includes missing values.\n",
        "*   The sum method adds together the Series's values.\n",
        "*   The product method multiplies together the Series's values.\n",
        "*   The mean method calculates the average of the Series's values.\n",
        "*   The std method calculates the standard deviation of the Series's values.\n",
        "*   The max method returns the largest value in the Series.\n",
        "*   The min method returns the smallest value in the Series.\n",
        "*   The median method returns the median of the Series (the value in the middle).\n",
        "*   The mode method returns the mode of the Series (the most frequent alue).\n",
        "*   The describe method returns a summary with various mathematical calculations.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wIvt6Qj0JP3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_data = pd.read_csv(\"/content/sample_data/google_stock_price.csv\", usecols=[\"Stock Price\"]).squeeze(\"columns\")\n",
        "print(\"-------------Type-----------------\")\n",
        "print(type(google_data))\n",
        "print(\"-------------Count-----------------\")\n",
        "print(google_data.count())\n",
        "print(\"-------------Size-----------------\")\n",
        "print(google_data.size)\n",
        "print(\"-------------Product-----------------\")\n",
        "print(google_data.product())\n",
        "print(\"-------------Mean-----------------\")\n",
        "print(google_data.mean())\n",
        "print(\"-------------Standard Deviation-----------------\")\n",
        "print(google_data.std())"
      ],
      "metadata": {
        "id": "uANmANHGKtBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Broadcasting\n",
        "\n",
        "\n",
        "\n",
        "*   Broadcasting describes the process ef applying an aritametic operation to an array (i.e, a Series).\n",
        "*   We can combine mathematical operators with a Series to apply the mathematical operation to every value.\n",
        "*   There are also methods to accomplish the same resuts (add, sub, mul, div, etc)"
      ],
      "metadata": {
        "id": "ZCbgC-ApN34p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_data = pd.read_csv(\"/content/sample_data/google_stock_price.csv\", usecols=[\"Stock Price\"]).squeeze(\"columns\")\n",
        "print(\"-------------Before Broadcasting : add 10-----------------\")\n",
        "print(google_data)\n",
        "print(\"-------------After Broadcasting : add 10-----------------\")\n",
        "google_data_after_broadcasting = google_data.add(10) # google_data + 10\n",
        "print(google_data_after_broadcasting)"
      ],
      "metadata": {
        "id": "1xppp_pBV94A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The value_counts Method\n",
        "\n",
        "\n",
        "*   The value_counts method returns the number of times each unique value occurs in the Series.\n",
        "*   The normalize parameter returns the relative frequencies/percentages of the values instead of the counts."
      ],
      "metadata": {
        "id": "Fs35-dhMl2cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pokeman_data = pd.read_csv(\"/content/sample_data/pokemon.csv\", index_col=[\"Pokemon\"]).squeeze('columns')\n",
        "print(pokeman_data.value_counts())\n",
        "print(pokeman_data.value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "6txGIO58mh7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The apply Method\n",
        "\n",
        "\n",
        "*   The apply method accepts a function. It invokes that function on every Series value.\n",
        "\n"
      ],
      "metadata": {
        "id": "gVHm88tPoJod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pokeman_data = pd.read_csv(\"/content/sample_data/pokemon.csv\", index_col=[\"Pokemon\"]).squeeze('columns')\n",
        "print(pokeman_data.apply(len))"
      ],
      "metadata": {
        "id": "FDQw6HNUoXfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The map Method\n",
        "\n",
        "\n",
        "\n",
        "*   The map method \"maps\" or connects each Series values to another value.\n",
        "\n",
        "*   We can pass the method a dictionary or a Series. Both types connects keys to values.\n",
        "*   The map method uses our argument to connect or bridge together the values.\n",
        "\n"
      ],
      "metadata": {
        "id": "MZXmvDVHq8SO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataframe\n",
        "\n",
        "*   A DataFrame is a 2-dimensional table consisting of rows and columns.\n",
        "*   Pandas uses a NaN designation for cells that have a missing value. It is short for \"not a number\". Most operations on NaN values will produce NaN values.\n",
        "*   Like with a Series, Pandas assigns an index position/label to each DataFrame row.\n",
        "*   The hasnans attribute exists only a Series. The columns attribute exists only on a DataFrame.\n",
        "*   Some methods/attributes will return different types of data.\n",
        "*   The info method returns a summary of the pandas object.\n"
      ],
      "metadata": {
        "id": "ZSOazbXP4jCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "print(nba_data)"
      ],
      "metadata": {
        "id": "ClKCSvVR5ZcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differences between Shared Methods\n",
        "\n",
        "\n",
        "*   The sum method adds a Series's values.\n",
        "*   On a DataFrame, the sum method defaults to adding the values by traversing the index (row values).\n",
        "*   The axis parameter customizes the direction that we add across. Pass \"columns\" or 1 to add \"across\" the columns."
      ],
      "metadata": {
        "id": "pHO7FefrohNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_data = pd.read_csv(\"/content/sample_data/revenue.csv\", index_col=\"Date\")\n",
        "print(revenue_data.sum(axis=\"index\"))\n",
        "print(\"----------------------------\")\n",
        "print(revenue_data.sum(axis=\"columns\"))\n",
        "print(\"--------------Sum of everything--------------\")\n",
        "print(revenue_data.sum(axis=\"columns\").sum())"
      ],
      "metadata": {
        "id": "ddb6C5iapLOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select One Column from a DataFrame\n",
        "\n",
        "\n",
        "*   We can use attribute syntax (df. column_name ) to select a column from a DataFrame. The syntax will not work if the column name has spaces.\n",
        "*   We can also use square bracket syntax ( df [\"column name\"] ) which will work for any column name.\n",
        "*   Pandas extracts a column from a DataFrame as a Series.\n",
        "*   The Series is a view, so changes to the Series will affect the DataFrame.\n",
        "*   Pandas will display a warning if you mutate the Series. Use the copy method to create a duplicate."
      ],
      "metadata": {
        "id": "Aa6gUKeL0wIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "print(nba_data.head())\n",
        "print(\"----------------------------\")\n",
        "print(nba_data.Name)\n",
        "print(\"----------------------------\")\n",
        "print(nba_data[\"Name\"])\n",
        "print(\"----------------------------\")\n",
        "print(nba_data[\"Name\"].copy())\n",
        "print(\"----------------------------\")\n",
        "print(nba_data.Team)\n",
        "print(\"----------------------------\")\n",
        "print(nba_data[\"Team\"])\n",
        "print(\"----------------------------\")\n",
        "print(nba_data[\"Team\"].copy())\n"
      ],
      "metadata": {
        "id": "r_tis5RAMsWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select Multiple Columns from a DataFrame\n",
        "\n",
        "*   Use square brackets with a list of names to extract multiple DataFrame columns.List item\n",
        "*   Pandas stores the result in a new DataFrame (a copy).\n",
        "\n"
      ],
      "metadata": {
        "id": "ypMRJ3VQPj3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "print(\"----------------------------\")\n",
        "print(nba_data[[\"Name\",\"Team\"]])"
      ],
      "metadata": {
        "id": "3YQCixpNWHhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add New Column to DataFrame\n",
        "\n",
        "\n",
        "*   Use square bracket extraction syntax with an equal sign to add a new Series to a DataFrame.\n",
        "*   The insert method allows us to insert an element at a specific column index.\n",
        "*   On the right-hand side, we can reference an existing DataFrame column and perform a broadcasting operation on it to create the new Series.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V83jiXr3Xz6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "print(nba_data.head())\n",
        "print(\"----------------------------\")\n",
        "nba_data[\"Sports\"] = \"Basketball\"\n",
        "print(nba_data.head())\n",
        "print(\"----------------------------\")\n",
        "nba_data.insert(loc=3, column=\"Sports-2\", value=\"Cricket\")\n",
        "print(nba_data.head())\n",
        "print(\"----------------------------\")\n",
        "nba_data[\"Salary Doubled\"] = nba_data[\"Salary\"] * 2\n",
        "print(nba_data.head())\n"
      ],
      "metadata": {
        "id": "SiYfFjhwa1Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Review of the value_counts Method\n",
        "\n",
        "*   The value_counts method counts the number of times that each unique value occurs in a Series.\n",
        "\n"
      ],
      "metadata": {
        "id": "1h8k5fw5nnvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "print(\"----------------------------\")\n",
        "print(nba_data[\"Position\"].value_counts())\n",
        "print(\"----------------------------\")\n",
        "print(nba_data[\"Position\"].value_counts(normalize=True))\n",
        "print(\"----------------------------\")\n",
        "print(nba_data[\"Position\"].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "id": "0SrVhHaj8wU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop Rows with Missing Values\n",
        "\n",
        "\n",
        "*   Pandas uses a NaN designation for cells that have a missing value.\n",
        "*   The dropna method deletes rows with missing values. Its default behavior is to remove a row if it has any missing values.\n",
        "\n",
        "*   Pass the how parameter an argument of \"all\" to delete rows where all the values are NaN.\n",
        "*   The subset parameters customizes/limits the columns that pandas will use to drop rows with missing values.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0iXJCbMrDiE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "\n",
        "print(nba_data.dropna())\n",
        "print(\"-----------------------------\")\n",
        "print(nba_data.dropna(how=\"all\"))\n",
        "print(\"-----------------------------\")\n",
        "print(nba_data.dropna(subset=\"College\"))\n",
        "print(\"-----------------------------\")\n",
        "print(nba_data.dropna(subset=[\"College\", \"Salary\"]))"
      ],
      "metadata": {
        "id": "8KpzD8I6FvUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fill in Missing Values with the fillna Method\n",
        "\n",
        "*   The fillna method replaces missing NaN values with its argument.\n",
        "*   The fillna method is available on both DataFrames and Series.\n",
        "*   An extracted Series is a view on the original DataFrame, but the fillna method returns a copy.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JtfcLwpaJfRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "nba_data = nba_data.fillna(0)\n",
        "print(nba_data)\n",
        "print(\"-----------------------------\")\n",
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "nba_data = nba_data[\"College\"].fillna(value=\"Unknown\")\n",
        "print(nba_data)"
      ],
      "metadata": {
        "id": "_OC6d0K4Jw48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The astype Method I\n",
        "\n",
        "\n",
        "*   The astype method converts a Series's values to a specified type.\n",
        "*   Pass in the specified type as either a string or the core Python data type.\n",
        "*   Pandas cannot convert NaN values to numeric types, so we need to eliminate/replace them before we perform the conversion.\n",
        "*   The dtypes attribute returns a Series with the DataFrame's columns and their types.\n",
        "\n"
      ],
      "metadata": {
        "id": "DOWnUVqZJgLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "nba_data.dropna(how=\"all\")\n",
        "nba_data[\"Salary\"] = nba_data[\"Salary\"].fillna(0)\n",
        "print(nba_data)\n",
        "print(\"-----------------------------\")\n",
        "print(nba_data.dtypes)\n",
        "print(\"-----------------------------\")\n",
        "nba_data[\"Salary\"]=nba_data[\"Salary\"].astype(int)\n",
        "print(nba_data)\n",
        "print(\"-----------------------------\")\n",
        "print(nba_data.dtypes)"
      ],
      "metadata": {
        "id": "1pKdlnyKLCvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The astype Method II\n",
        "\n",
        "\n",
        "*   The category type is ideal for columns with a limited number of unique values.\n",
        "*   The nunique method will return a Series with the number of unique values in each column.\n",
        "*   With categories, pandas does not create a separate value in memory for each \"cell\". Rather, the cells point to a single copy for each unique value.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9bidpkGZOB1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "nba_data.dropna(how=\"all\")\n",
        "print(nba_data[\"Team\"].unique())\n",
        "print(\"-----------------------------\")\n",
        "print(nba_data.info)\n",
        "print(\"-----------------------------\")\n",
        "nba_data[\"Position\"] = nba_data[\"Position\"].astype(\"category\")\n",
        "nba_data[\"Team\"] = nba_data[\"Team\"].astype(\"category\")\n",
        "print(nba_data.info)"
      ],
      "metadata": {
        "id": "T4Tr-NqmQk82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sort a DataFrame with the sort_values Method I\n",
        "\n",
        "*   The sort_values method sorts a DataFrame by the values in one or more columns. The default sort is an ascending one (alphabetical for strings).\n",
        "*   The first parameter ( by ) expects the column(s) to sort by.\n",
        "*   If sorting by a single column, pass a string with its name.\n",
        "*   The ascending parameter customizes the sort order.\n",
        "*   The na_position parameter customizes where pandas places NaN values.\n"
      ],
      "metadata": {
        "id": "_4dTCJFpcnVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "nba_data[\"Name\"].sort_values()\n",
        "print(\"---------------------------\")\n",
        "print(nba_data.sort_values(by=\"Name\", ascending=True ))\n",
        "print(\"---------------------------\")\n",
        "print(nba_data.sort_values(by=\"Salary\", na_position=\"first\" ))"
      ],
      "metadata": {
        "id": "72_3L9JIeVeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sort a DataFrame with the sort_values Method II\n",
        "\n",
        "\n",
        "*   To sort by multiple columns, pass the by parameter a list of column names. Pandas will sort in the specified column order (first to last).\n",
        "\n",
        "*   Pass the ascending parameter a Boolean to sort all columns in a consistent order (all ascending or all descending).\n",
        "*   Pass ascending a list to customize the sort order per column. The ascending list length must match the by list.\n",
        "\n"
      ],
      "metadata": {
        "id": "zQorGwq7jKmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "nba_data.sort_values(by=[\"Team\", \"Name\"])\n",
        "nba_data.sort_values(by=[\"Team\", \"Name\"], ascending=False)\n",
        "nba_data.sort_values(by=[\"Team\", \"Name\"], ascending=[False, True])"
      ],
      "metadata": {
        "id": "E2L4H0w9mDBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sort a DataFrame by its Index\n",
        "\n",
        "*   The sort_index method sorts the DataFrame by its index positions/labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "VdJpJyIvpJq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\")\n",
        "print(nba_data.sort_values(by=[\"Team\", \"Name\"]))\n",
        "print(\"---------------------------\")\n",
        "print(nba_data.sort_index())\n",
        "print(\"---------------------------\")\n",
        "print(nba_data.sort_index(ascending=True))\n",
        "print(\"---------------------------\")\n",
        "print(nba_data.sort_index(ascending=False))"
      ],
      "metadata": {
        "id": "nMjVlSTWpxPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rank Values with the rank Method\n",
        "\n",
        "\n",
        "*   The rank method assigns a numeric ranking to each Series value.\n",
        "*   Pandas will assign the same rank to equal values and create a \"gap\" in the dataset for the ranks.\n",
        "\n"
      ],
      "metadata": {
        "id": "_JjDrqqpuIM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nba_data = pd.read_csv(\"/content/sample_data/nba.csv\").dropna(how=\"all\")\n",
        "nba_data[\"Salary\"]=nba_data[\"Salary\"].fillna(0).astype(int)\n",
        "#print(nba_data.sort_values(by=[\"Team\", \"Name\"]))\n",
        "nba_data[\"Salary Rank\"] = nba_data[\"Salary\"].rank(ascending=True).astype(int)\n",
        "nba_data.sort_values(\"Salary Rank\", ascending=True).head(10)"
      ],
      "metadata": {
        "id": "--T1X364zvsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataFrames II: Filtering Data\n",
        "\n",
        "### This Module's Dataset + Memory Optimization\n",
        "\n",
        "*   The pd.to_datetime method converts a Series to hold datetime values.\n",
        "*   The format parameter informs pandas of the format that the times are stored in.\n",
        "*   We pass symbols designating the segments of the string. For example, %m means \"month\" and %d means day.\n",
        "*   The dt attribute reveals an object with many datetime-related attributes and methods.\n",
        "*   The dt.time attribute extracts only the time from each value in a datetime Series.\n",
        "\n",
        "*   Use the astype method to convert the values in a Series to another type.\n",
        "*   The parse_dates parameter of read_csv is an alternate way to parse strings as datetimes.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8XW5u41VVxMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employees_data = pd.read_csv(\"/content/sample_data/employees.csv\")\n",
        "print(employees_data.info())\n",
        "print(\"-------------------------\")\n",
        "employees_data[\"Start Date\"] = pd.to_datetime(employees_data[\"Start Date\"], format=\"mixed\")\n",
        "employees_data[\"Last Login Time\"] = pd.to_datetime(employees_data[\"Last Login Time\"], format=\"mixed\").dt.time\n",
        "employees_data[\"Senior Management\"] = employees_data[\"Senior Management\"].astype(bool)\n",
        "employees_data[\"Gender\"] = employees_data[\"Gender\"].astype(\"category\")\n",
        "print(employees_data.info())"
      ],
      "metadata": {
        "id": "bhJZ0E3RXpJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter A DataFrame Based On A Condition\n",
        "\n",
        "\n",
        "*   Pandas needs a Series of Booleans to perform a filter.\n",
        "*   Pass the Boolean Series inside square brackets after the DataFrame.\n",
        "*   We can generate a Boolean Series using a wide variety of operations (equality, inequality, less than, greater than, inclusion, etc)"
      ],
      "metadata": {
        "id": "AWnv6A2X_a4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employees_data = pd.read_csv(\"/content/sample_data/employees.csv\")\n",
        "print(employees_data[employees_data[\"Gender\"] == \"Male\"])\n",
        "print(\"---------------------\")\n",
        "print(employees_data[employees_data[\"Team\"] == \"Finance\"])\n",
        "print(\"---------------------\")\n",
        "employees_data[\"Senior Management\"] = employees_data[\"Senior Management\"].astype(bool)\n",
        "print(employees_data[employees_data[\"Senior Management\"]])"
      ],
      "metadata": {
        "id": "NRP59YkJBon_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Date time"
      ],
      "metadata": {
        "id": "4NEkXnaEJMsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt.time(hour=6, minute=50, second=30)"
      ],
      "metadata": {
        "id": "1E_UhhV4JPMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter with More than One Condition (AND)\n",
        "\n",
        "*   Add the \"&\" operator in between two Boolean Series to filter by multiple conditions.\n",
        "*   We can assign the Series to variables to make the syntax more readable.\n",
        "\n"
      ],
      "metadata": {
        "id": "UXfvP7OzK8Ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter with More than One Condition (OR)\n",
        "\n",
        "*   Use the | operator in between two Boolean Series to filter by either condition.\n",
        "\n"
      ],
      "metadata": {
        "id": "0fP6E5cQPLWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The isin Method\n",
        "\n",
        "*   The isin Series method accepts a collection object like a list, tuple, or Series.\n",
        "*   The method returns True for a row if its value is found in the collection.\n",
        "\n"
      ],
      "metadata": {
        "id": "zAwTmPuHP_Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employees_data = pd.read_csv(\"/content/sample_data/employees.csv\")\n",
        "employees_data[employees_data[\"Team\"].isin([\"Marketing\", \"Finance\"])]"
      ],
      "metadata": {
        "id": "e0KlKicIQPiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The isnull and notnull Methods\n",
        "\n",
        "*   The isnull method returns True for NaN values in a Series.\n",
        "*   The notnull method returns True for present values in a Series.\n",
        "\n"
      ],
      "metadata": {
        "id": "MVF_FeOKSypL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employees_data = pd.read_csv(\"/content/sample_data/employees.csv\")\n",
        "print(employees_data[employees_data[\"Team\"].isnull()])\n",
        "print(\"---------------------\")\n",
        "print(employees_data[employees_data[\"Team\"].notnull()])"
      ],
      "metadata": {
        "id": "o87ejrUlTIJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The between Method\n",
        "\n",
        "\n",
        "*   The between method returns True if a Series value is found within its range.\n",
        "\n"
      ],
      "metadata": {
        "id": "5hUUp1gKUIBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employees_data = pd.read_csv(\"/content/sample_data/employees.csv\")\n",
        "print(employees_data[employees_data[\"Salary\"].between(60000,61000)])\n",
        "print(\"------------------------------\")\n",
        "print(employees_data[employees_data[\"Bonus %\"].between(2.5,2.6)])\n",
        "print(\"------------------------------\")\n",
        "employees_data[\"Start Date\"] = pd.to_datetime(employees_data[\"Start Date\"], format=\"mixed\")\n",
        "print(employees_data[employees_data[\"Start Date\"].between(\"1998-11-01\",\"1999-01-01\")])\n",
        "print(\"------------------------------\")\n",
        "employees_data[\"Last Login Time\"] =pd.to_datetime(employees_data[\"Last Login Time\"]).to_timestamp\n",
        "print(employees_data[employees_data[\"Last Login Time\"].between(dt.time(1,10), dt.time(2,0))])\n"
      ],
      "metadata": {
        "id": "3BYpUcBzexDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The duplicated Method\n",
        "\n",
        "\n",
        "\n",
        "*   The duplicated method returns True if a Series value is a duplicate.\n",
        "\n",
        "*   Pandas will mark one occurrence of a repeated value as a non-duplicate.\n",
        "\n",
        "*   Use the keep parameter to designate whether the first or last occurrence of a repeated value should be considered the \"non-duplicate\".\n",
        "*   Pass False to the keep parameter to mark all occurrences of repeated values as duplicates.\n",
        "\n",
        "\n",
        "*   Use the tilde symbol ( ~ ) to invert a Series's values. Trues will become Falses, and Falses will become trues.\n",
        "\n"
      ],
      "metadata": {
        "id": "rWM01jUhtCoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employees_data = pd.read_csv(\"/content/sample_data/employees.csv\")\n",
        "print(employees_data[employees_data[\"First Name\"].duplicated()])\n",
        "print(\"------------------------------\")\n",
        "print(employees_data[employees_data[\"First Name\"].duplicated(keep=\"first\")])\n",
        "print(\"------------------------------\")\n",
        "print(employees_data[employees_data[\"First Name\"].duplicated(keep=\"last\")])\n",
        "print(\"------------------------------\")\n",
        "print(employees_data[employees_data[\"First Name\"].duplicated(keep=False)])\n",
        "print(\"--------------Invert----------------\")\n",
        "print(employees_data[~employees_data[\"First Name\"].duplicated(keep=False)])"
      ],
      "metadata": {
        "id": "ZIXP_nM7zVM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The drop_duplicates Method\n",
        "\n",
        "\n",
        "*   The drop_duplicates method deletes rows with duplicate values.\n",
        "*   By default, it will remove a row if all of its values are shared with another row.\n",
        "*   The subset parameter configures the columns to look for duplicate values within.\n",
        "*   Pass a list to subset parameter to look for duplicates across multiple columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "tDJ7xf9T3Lvq"
      }
    }
  ]
}